name: list-model-invocation-jobs
description: Lists all batch inference jobs in the account.
flags:
    --cli-input-json=: Read arguments from the JSON string provided
    --cli-input-yaml=: Read arguments from the YAML string provided
    --generate-cli-skeleton: Prints a JSON skeleton to standard output without sending an API request
    --max-results=: The maximum number of results to return.
    --name-contains=: Specify a string to filter for batch inference jobs whose names contain the string.
    --next-token=: If there were more results than the value you specified in the `maxResults` field in a previous `ListModelInvocationJobs` request, the response would have returned a `nextToken` value.
    --sort-by=: An attribute by which to sort the results.
    --sort-order=: Specifies whether to sort the results by ascending or descending order.
    --status-equals=: Specify a status to filter for batch inference jobs whose statuses match the string you specify.
    --submit-time-after=: Specify a time to filter for batch inference jobs that were submitted after the time you specify.
    --submit-time-before=: Specify a time to filter for batch inference jobs that were submitted before the time you specify.
completion:
    flag:
        sort-by:
            - CreationTime
        sort-order:
            - Ascending
            - Descending
        status-equals:
            - Submitted
            - InProgress
            - Completed
            - Failed
            - Stopping
            - Stopped
            - PartiallyCompleted
            - Expired
            - Validating
            - Scheduled
