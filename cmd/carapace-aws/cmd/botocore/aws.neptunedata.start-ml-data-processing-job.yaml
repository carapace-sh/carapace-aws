name: start-ml-data-processing-job
description: Creates a new Neptune ML data processing job for processing the graph data exported from Neptune for training.
flags:
    --cli-input-json=: Read arguments from the JSON string provided
    --cli-input-yaml=: Read arguments from the YAML string provided
    --config-file-name=: A data specification file that describes how to load the exported graph data for training.
    --generate-cli-skeleton: Prints a JSON skeleton to standard output without sending an API request
    --id=: A unique identifier for the new job.
    --input-data-s3-location=!: The URI of the Amazon S3 location where you want SageMaker to download the data needed to run the data processing job.
    --model-type=: 'One of the two model types that Neptune ML currently supports: heterogeneous graph models (`heterogeneous`), and knowledge graph (`kge`).'
    --neptune-iam-role-arn=: The Amazon Resource Name (ARN) of an IAM role that SageMaker can assume to perform tasks on your behalf.
    --previous-data-processing-job-id=: The job ID of a completed data processing job run on an earlier version of the data.
    --processed-data-s3-location=!: The URI of the Amazon S3 location where you want SageMaker to save the results of a data processing job.
    --processing-instance-type=: The type of ML instance used during data processing.
    --processing-instance-volume-size-in-gb=: The disk volume size of the processing instance.
    --processing-time-out-in-seconds=: Timeout in seconds for the data processing job.
    --s3-output-encryption-kms-key=: The Amazon Key Management Service (Amazon KMS) key that SageMaker uses to encrypt the output of the processing job.
    --sagemaker-iam-role-arn=: The ARN of an IAM role for SageMaker execution.
    --security-group-ids=: The VPC security group IDs.
    --subnets=: The IDs of the subnets in the Neptune VPC.
    --volume-encryption-kms-key=: The Amazon Key Management Service (Amazon KMS) key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instances that run the training job.
