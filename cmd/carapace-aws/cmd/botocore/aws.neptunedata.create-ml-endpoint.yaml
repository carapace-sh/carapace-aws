name: create-ml-endpoint
description: Creates a new Neptune ML inference endpoint that lets you query one specific model that the model-training process constructed.
flags:
    --cli-input-json=: Read arguments from the JSON string provided.
    --cli-input-yaml=: Read arguments from the YAML string provided.
    --generate-cli-skeleton: Prints a JSON skeleton to standard output without sending an API request.
    --id=: A unique identifier for the new inference endpoint.
    --instance-count=: The minimum number of Amazon EC2 instances to deploy to an endpoint for prediction.
    --instance-type=: The type of Neptune ML instance to use for online servicing.
    --ml-model-training-job-id=: The job Id of the completed model-training job that has created the model that the inference endpoint will point to.
    --ml-model-transform-job-id=: The job Id of the completed model-transform job.
    --model-name=: Model type for training.
    --neptune-iam-role-arn=: The ARN of an IAM role providing Neptune access to SageMaker and Amazon S3 resources.
    --no-update: If set to `true`, `update` indicates that this is an update request.
    --update: If set to `true`, `update` indicates that this is an update request.
    --volume-encryption-kms-key=: The Amazon Key Management Service (Amazon KMS) key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instances that run the training job.
