name: list-inference-schedulers
description: Retrieves a list of all inference schedulers currently available for your account.
flags:
    --cli-input-json=: Read arguments from the JSON string provided.
    --cli-input-yaml=: Read arguments from the YAML string provided.
    --generate-cli-skeleton: Prints a JSON skeleton to standard output without sending an API request.
    --inference-scheduler-name-begins-with=: The beginning of the name of the inference schedulers to be listed.
    --max-results=: Specifies the maximum number of inference schedulers to list.
    --model-name=: The name of the machine learning model used by the inference scheduler to be listed.
    --next-token=: An opaque pagination token indicating where to continue the listing of inference schedulers.
    --status=: Specifies the current status of the inference schedulers.
completion:
    flag:
        status:
            - PENDING
            - RUNNING
            - STOPPING
            - STOPPED
