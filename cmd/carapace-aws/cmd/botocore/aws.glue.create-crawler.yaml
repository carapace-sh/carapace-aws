name: create-crawler
description: Creates a new crawler with specified targets, role, configuration, and optional schedule.
flags:
    --classifiers=: A list of custom classifiers that the user has registered.
    --cli-input-json=: Read arguments from the JSON string provided.
    --cli-input-yaml=: Read arguments from the YAML string provided.
    --configuration=: Crawler configuration information.
    --crawler-security-configuration=: The name of the `SecurityConfiguration` structure to be used by this crawler.
    --database-name=: 'The Glue database where results are written, such as: `arn:aws:daylight:us-east-1::database/sometable/*`.'
    --description=: A description of the new crawler.
    --generate-cli-skeleton: Prints a JSON skeleton to standard output without sending an API request.
    --lake-formation-configuration=: Specifies Lake Formation configuration settings for the crawler.
    --lineage-configuration=: Specifies data lineage configuration settings for the crawler.
    --name=!: Name of the new crawler.
    --recrawl-policy=: A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.
    --role=!: The IAM role or Amazon Resource Name (ARN) of an IAM role used by the new crawler to access customer resources.
    --schedule=: 'A `cron` expression used to specify the schedule (see [Time-Based Schedules for Jobs and Crawlers](https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html). For example, to run something every day at 12:15 UTC, you would specify: `cron(15 12 * * ?'
    --schema-change-policy=: The policy for the crawler's update and deletion behavior.
    --table-prefix=: The table prefix used for catalog tables that are created.
    --tags=: The tags to use with this crawler request.
    --targets=!: A list of collection of targets to crawl.
