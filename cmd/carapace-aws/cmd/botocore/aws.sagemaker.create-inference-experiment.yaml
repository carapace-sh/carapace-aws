name: create-inference-experiment
description: Creates an inference experiment using the configurations specified in the request.
flags:
    --cli-input-json=: Read arguments from the JSON string provided
    --cli-input-yaml=: Read arguments from the YAML string provided
    --data-storage-config=: The Amazon S3 location and configuration for storing inference request and response data.
    --description=: A description for the inference experiment.
    --endpoint-name=!: The name of the Amazon SageMaker endpoint on which you want to run the inference experiment.
    --generate-cli-skeleton: Prints a JSON skeleton to standard output without sending an API request
    --kms-key=: The Amazon Web Services Key Management Service (Amazon Web Services KMS) key that Amazon SageMaker uses to encrypt data on the storage volume attached to the ML compute instance that hosts the endpoint.
    --model-variants=!: An array of `ModelVariantConfig` objects.
    --name=!: The name for the inference experiment.
    --role-arn=!: The ARN of the IAM role that Amazon SageMaker can assume to access model artifacts and container images, and manage Amazon SageMaker Inference endpoints for model deployment.
    --schedule=: The duration for which you want the inference experiment to run.
    --shadow-mode-config=!: The configuration of `ShadowMode` inference experiment type.
    --tags=: Array of key-value pairs.
    --type=!: The type of the inference experiment that you want to run.
completion:
    flag:
        type:
            - ShadowMode
