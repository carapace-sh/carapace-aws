name: invoke-model
description: Invokes the specified Amazon Bedrock model to run inference using the prompt and inference parameters provided in the request body.
flags:
    --accept=: The desired MIME type of the inference body in the response.
    --body=: The prompt and inference parameters in the format specified in the `contentType` in the header.
    --cli-input-json=: Read arguments from the JSON string provided
    --cli-input-yaml=: Read arguments from the YAML string provided
    --content-type=: The MIME type of the input data in the request.
    --generate-cli-skeleton: Prints a JSON skeleton to standard output without sending an API request
    --guardrail-identifier=: The unique identifier of the guardrail that you want to use.
    --guardrail-version=: The version number for the guardrail.
    --model-id=!: The unique identifier of the model to invoke to run inference.
    --performance-config-latency=: Model performance settings for the request.
    --trace=: Specifies whether to enable or disable the Bedrock trace.
completion:
    flag:
        performance-config-latency:
            - standard
            - optimized
        trace:
            - ENABLED
            - DISABLED
            - ENABLED_FULL
